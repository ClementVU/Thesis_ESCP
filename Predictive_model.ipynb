{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "55nKwRXEQwkk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Consulting_survey_DataSet (3).csv')"
      ],
      "metadata": {
        "id": "LoexEfy6QxWu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available columns in dataset:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGE014V8Qy0S",
        "outputId": "3ccf7568-303b-43c4-e655-eb110ccce92f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns in dataset:\n",
            "['Timestamp', 'Do you CURRENTLY work at a consulting firm?', 'Which firm do you CURRENTLY work for?', 'Are you CURRENTLY in a Commercial or Federal practice? ', 'What is your CURRENT title (or equivalent)? ', 'What COUNTRY are you CURRENTLY based out of?', 'What is your CURRENT annual base compensation in USD (not including bonuses, perks, or other incentives)? Please consult Google for conversion tools for local currency into USD. Enter number values only.', 'What is the total amount in USD of BONUSES you estimate you will receive in 2021? Enter number only.', 'Expected total compensation (calculated)', 'How many hours per week on AVERAGE do you work (including non-billable time)?', 'Have you gotten an OFFER from another company this year?', 'Was the offer from another CONSULTING FIRM?', 'Which firm was the HIGHEST (base compensation) OFFER from?', 'Was the OFFER for a Commercial or Federal practice? ', 'What was the OFFERED title (or equivalent)? ', 'What COUNTRY was the OFFER based out of?', 'What was the HIGHEST OFFERED annual base compensation in USD (not including bonuses, perks, or other incentives)? Please consult Google for conversion tools for local currency into USD. Enter a number only.', 'What was the total annual BONUS OFFERED?', 'Did you accept the offer?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total entries before filtering: {df.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKI5S_zXQ1Sh",
        "outputId": "6ba01071-881d-49eb-9808-9c5775afff64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total entries before filtering: 4200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[df['Have you gotten an OFFER from another company this year?'] == 'Yes'].copy()"
      ],
      "metadata": {
        "id": "vh4lCoS2Q2CT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Entries with offers: {df_filtered.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYQrIEE4Q265",
        "outputId": "1ca0a93c-39c6-45b7-cf3f-3a70f008cbbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entries with offers: 1112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns available in dataset after filtering:\")\n",
        "print(df_filtered.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBWBl2WPQ4m9",
        "outputId": "79e0db51-bb68-426d-f25e-9d0a33358676"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns available in dataset after filtering:\n",
            "['Timestamp', 'Do you CURRENTLY work at a consulting firm?', 'Which firm do you CURRENTLY work for?', 'Are you CURRENTLY in a Commercial or Federal practice? ', 'What is your CURRENT title (or equivalent)? ', 'What COUNTRY are you CURRENTLY based out of?', 'What is your CURRENT annual base compensation in USD (not including bonuses, perks, or other incentives)? Please consult Google for conversion tools for local currency into USD. Enter number values only.', 'What is the total amount in USD of BONUSES you estimate you will receive in 2021? Enter number only.', 'Expected total compensation (calculated)', 'How many hours per week on AVERAGE do you work (including non-billable time)?', 'Have you gotten an OFFER from another company this year?', 'Was the offer from another CONSULTING FIRM?', 'Which firm was the HIGHEST (base compensation) OFFER from?', 'Was the OFFER for a Commercial or Federal practice? ', 'What was the OFFERED title (or equivalent)? ', 'What COUNTRY was the OFFER based out of?', 'What was the HIGHEST OFFERED annual base compensation in USD (not including bonuses, perks, or other incentives)? Please consult Google for conversion tools for local currency into USD. Enter a number only.', 'What was the total annual BONUS OFFERED?', 'Did you accept the offer?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Focus only on \"Did you accept the offer?\" column and filter valid responses\n",
        "df_filtered = df_filtered[df_filtered['Did you accept the offer?'].isin(['Yes', 'No'])]"
      ],
      "metadata": {
        "id": "jgimUcP-Q6L-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert target variable into binary (1 = Accepted, 0 = Not Accepted)\n",
        "df_filtered['Did you accept the offer?'] = df_filtered['Did you accept the offer?'].map({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZYa9Td-Q95p",
        "outputId": "135e26db-3868-436d-ee48-60fe8e1aff50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-457f93d9aa50>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_filtered['Did you accept the offer?'] = df_filtered['Did you accept the offer?'].map({'Yes': 1, 'No': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define numerical feature list, ensuring only available columns are used\n",
        "possible_num_features = [\n",
        "    'What is your CURRENT annual base compensation in USD (not including bonuses, perks, or other incentives)? Please consult Google for conversion tools for local currency into USD. Enter number values only.',\n",
        "    'What is the total amount in USD of BONUSES you estimate you will receive in 2021? Enter number only.',\n",
        "    'Expected total compensation (calculated)',\n",
        "    'How many hours per week on AVERAGE do you work (including non-billable time)?',\n",
        "    'What was the HIGHEST OFFERED annual base compensation in USD (not including bonuses, perks, or other incentives)?',\n",
        "    'What was the total annual BONUS OFFERED?'\n",
        "]\n",
        "num_features = [col for col in possible_num_features if col in df_filtered.columns]\n",
        "print(\"Numerical features being used:\", num_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbsmTlPXQ_hC",
        "outputId": "4df1ded2-97ef-4dc9-c05a-1b524d67e616"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical features being used: ['What is your CURRENT annual base compensation in USD (not including bonuses, perks, or other incentives)? Please consult Google for conversion tools for local currency into USD. Enter number values only.', 'What is the total amount in USD of BONUSES you estimate you will receive in 2021? Enter number only.', 'Expected total compensation (calculated)', 'How many hours per week on AVERAGE do you work (including non-billable time)?', 'What was the total annual BONUS OFFERED?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle non-numeric values in numerical columns\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        value = value.strip()\n",
        "        if \"-\" in value:\n",
        "            parts = value.split(\"-\")\n",
        "            try:\n",
        "                return (float(parts[0]) + float(parts[1])) / 2\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "        elif value.replace(\".\", \"\").isdigit():\n",
        "            return float(value)\n",
        "        else:\n",
        "            return np.nan\n",
        "    return value\n"
      ],
      "metadata": {
        "id": "AT_VuQ7YRB26"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply conversion to all numerical features\n",
        "for col in num_features:\n",
        "    df_filtered[col] = df_filtered[col].apply(convert_to_numeric)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjLV4jeRRGB3",
        "outputId": "9b74b741-7aaf-4538-817f-b5d721a693c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-d16ed050589f>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_filtered[col] = df_filtered[col].apply(convert_to_numeric)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with column mean\n",
        "df_filtered[num_features] = df_filtered[num_features].fillna(df_filtered[num_features].mean())\n",
        "\n",
        "# Check if categorical columns exist before proceeding\n",
        "possible_cat_features = ['What COUNTRY are you CURRENTLY based out of?', 'What is your CURRENT title (or equivalent)?',\n",
        "                         'Are you CURRENTLY in a Commercial or Federal practice?', 'Was the OFFER for a Commercial or Federal practice?']\n",
        "cat_features = [col for col in possible_cat_features if col in df_filtered.columns]\n",
        "\n",
        "if not cat_features:\n",
        "    print(\"Warning: No categorical features found in the dataset!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsWShjMuRIiQ",
        "outputId": "57df393d-41d2-47ae-c5eb-4ae7534e76c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-b8a04da1d987>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_filtered[num_features] = df_filtered[num_features].fillna(df_filtered[num_features].mean())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical features using OneHotEncoder if available\n",
        "if cat_features:\n",
        "    df_encoded = pd.get_dummies(df_filtered[cat_features], drop_first=True)\n",
        "    X = pd.concat([df_filtered[num_features], df_encoded], axis=1)\n",
        "else:\n",
        "    X = df_filtered[num_features]\n",
        "\n",
        "y = df_filtered['Did you accept the offer?']\n"
      ],
      "metadata": {
        "id": "oN7Z5pWSRLLW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X[num_features] = scaler.fit_transform(X[num_features])"
      ],
      "metadata": {
        "id": "BK3-7ITGRMbe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "H1CubNEsROlL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "4aysb7tQRP_5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print class distribution after resampling\n",
        "print(\"Class distribution after resampling:\")\n",
        "print(pd.Series(y_train_resampled).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbBEGQYQRR3n",
        "outputId": "cc2ad61c-98b6-4832-ba16-9192c2623ade"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after resampling:\n",
            "Did you accept the offer?\n",
            "0    504\n",
            "1    504\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models with hyperparameter tuning\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "}\n"
      ],
      "metadata": {
        "id": "3Pc9kBLYRTwB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    \"Random Forest\": {'n_estimators': [100, 200], 'max_depth': [10, 20], 'min_samples_split': [2, 5]},\n",
        "    \"Gradient Boosting\": {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1], 'max_depth': [3, 5]},\n",
        "}\n"
      ],
      "metadata": {
        "id": "Mtrnlm6_RVeI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, optimize, and evaluate models using Stratified K-Fold Cross-Validation\n",
        "best_model_name = None\n",
        "best_model_f1 = 0\n",
        "best_model_instance = None\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nOptimizing {name}...\")\n",
        "    if name in param_grid:\n",
        "        grid_search = GridSearchCV(model, param_grid[name], cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
        "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "        best_model = grid_search.best_estimator_\n",
        "        print(f\"Best Parameters for {name}: {grid_search.best_params_}\")\n",
        "    else:\n",
        "        best_model = model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"\\n{name} Classification Report:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Track the best model based on F1-score\n",
        "    if f1 > best_model_f1:\n",
        "        best_model_f1 = f1\n",
        "        best_model_name = name\n",
        "        best_model_instance = best_model\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name} with F1 Score: {best_model_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc0fFbvBRX2r",
        "outputId": "0b8e933d-3f57-40b8-9a05-45b54b39c4cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizing Random Forest...\n",
            "Best Parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "Random Forest Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       127\n",
            "           1       0.41      0.37      0.39        52\n",
            "\n",
            "    accuracy                           0.66       179\n",
            "   macro avg       0.58      0.58      0.58       179\n",
            "weighted avg       0.65      0.66      0.66       179\n",
            "\n",
            "F1 Score: 0.3878\n",
            "\n",
            "Optimizing Gradient Boosting...\n",
            "Best Parameters for Gradient Boosting: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
            "\n",
            "Gradient Boosting Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.70      0.73       127\n",
            "           1       0.39      0.46      0.42        52\n",
            "\n",
            "    accuracy                           0.63       179\n",
            "   macro avg       0.57      0.58      0.58       179\n",
            "weighted avg       0.65      0.63      0.64       179\n",
            "\n",
            "F1 Score: 0.4211\n",
            "\n",
            "Optimizing Logistic Regression...\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.56      0.65       127\n",
            "           1       0.37      0.63      0.47        52\n",
            "\n",
            "    accuracy                           0.58       179\n",
            "   macro avg       0.58      0.60      0.56       179\n",
            "weighted avg       0.67      0.58      0.60       179\n",
            "\n",
            "F1 Score: 0.4681\n",
            "\n",
            "Best Model: Logistic Regression with F1 Score: 0.4681\n"
          ]
        }
      ]
    }
  ]
}